{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69092c31-a2f2-4fe5-b728-3a9edf6382d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ba894ae0-7390-4911-8c4d-c41e12d1d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs = torch.load('./experiments/exp-3/data/vocabs.pt')\n",
    "_dataset = torch.load('./experiments/exp-3/data/dataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "1cc689a0-b381-4c2f-bb44-3a859310617a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rotowire(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.vocabs = torch.load('./experiments/exp-3/data/vocabs.pt')\n",
    "        _dataset = torch.load('./experiments/exp-3/data/dataset.pt') \n",
    "        batch_size = 4\n",
    "        self._dataset={'train':self.build_dataloader('train',_dataset,batch_size),\n",
    "                       'valid':self.build_dataloader('valid',_dataset,batch_size),\n",
    "                       'test':self.build_dataloader('test',_dataset,batch_size),\n",
    "                      }\n",
    "        \n",
    "        \n",
    "    @property\n",
    "    def vocab_size(self): return len(self.vocabs['idx2word'])\n",
    "    \n",
    "    def build_dataloader(self, setname, dataset, batch_size):\n",
    "        dataset = _Rotowire(setname, dataset, self.vocabs['word2idx']['<pad>'])\n",
    "        \n",
    "        return DataLoader(dataset, batch_size=batch_size, shuffle=(setname=='train'), collate_fn=dataset.get_collate_fn())\n",
    "    def post_process(self, batch, name=\"test\"):\n",
    "        \"\"\"\n",
    "        batch:\n",
    "            predictions: [batch, max_tlen], type: numpy\n",
    "            attetion_maps: [batch, max_tlen, max_slen], type: numpy\n",
    "            p_gens: [batch, max_tlen], type: numpy\n",
    "        return:\n",
    "            post_process: [batch, max_tlen], type list\n",
    "            predictions: [batch, max_tlen], type: numpy\n",
    "            attetion_maps: [batch, max_tlen, max_slen], type: numpy\n",
    "            p_gens: [batch, max_tlen], type: numpy            \n",
    "            \n",
    "        \"\"\"\n",
    "        post_process = []\n",
    "        if name == \"valid\":            \n",
    "            for predictions, tlen in zip(batch['predictions'], batch['tgt_lengths']):\n",
    "                post_process_=[]\n",
    "                for idx, word_idx in enumerate(predictions):\n",
    "                    if word_idx != self.vocabs['word2idx']['<eos>'] and  idx < tlen:\n",
    "                        post_process_.append(self.vocabs['idx2word'][word_idx])\n",
    "                    else:\n",
    "                        break\n",
    "                post_process.append(post_process_)\n",
    "        elif name == \"test\":\n",
    "            for predictions in batch['predictions']:\n",
    "                post_process_=[]\n",
    "                for idx in predictions:\n",
    "                    if idx != self.vocabs['word2idx']['<eos>']:\n",
    "                        post_process_.append(self.vocabs['idx2word'][idx])\n",
    "                    else:\n",
    "                        break\n",
    "                post_process.append(post_process_)\n",
    "\n",
    "        batch['post_process'] = post_process     \n",
    "        \n",
    "        return batch\n",
    "    \n",
    "class _Rotowire(Dataset):\n",
    "    def __init__(self, setname, dataset, pad):\n",
    "        self.setname = setname\n",
    "        self._dataset = dataset[setname]\n",
    "        self.pad = pad\n",
    "\n",
    "    def get_collate_fn(self):\n",
    "        if self.setname == 'train' or self.setname == 'valid':\n",
    "            def fn(batch):\n",
    "                \"\"\"\n",
    "                data = [('src_k', 'src_v', ...), ...]\n",
    "                \"\"\"\n",
    "                src_k, src_v,  src_lengths, tgt, tgt_lengths, alignment, template, template_lengths = zip(*batch)\n",
    "\n",
    "                ## padding\n",
    "                src_k = pad_sequence([torch.tensor(data) for data in src_k], batch_first=True , padding_value=self.pad)\n",
    "                src_v = pad_sequence([torch.tensor(data) for data in src_v], batch_first=True , padding_value=self.pad)\n",
    "                tgt = pad_sequence([torch.tensor(data) for data in tgt], batch_first=True , padding_value=self.pad)\n",
    "                alignment = pad_sequence([torch.tensor(data) for data in alignment], batch_first=True , padding_value=-1)\n",
    "                template = pad_sequence([torch.tensor(data) for data in template], batch_first=True , padding_value=self.pad)  \n",
    "\n",
    "                ## convert\n",
    "                alignment[alignment==-1] = src_k.size(1) # replace with max slen + 1\n",
    "                src_lengths = torch.tensor(src_lengths)\n",
    "                tgt_lengths = torch.tensor(tgt_lengths)\n",
    "                template_lengths = torch.tensor(template_lengths)\n",
    "\n",
    "                batch = {'src_k':src_k, \n",
    "                         'src_v':src_v, \n",
    "                         'src_lengths':src_lengths, \n",
    "                         'tgt':tgt, \n",
    "                         'tgt_lengths':tgt_lengths, \n",
    "                         'alignment':alignment,\n",
    "                         'template':template, \n",
    "                         'template_lengths':template_lengths,\n",
    "                        }\n",
    "\n",
    "                return batch\n",
    "            return fn\n",
    "        elif self.setname == 'test':\n",
    "            def fn(batch):\n",
    "                \"\"\"\n",
    "                data = [('src_k', 'src_v', ...), ...]\n",
    "                \"\"\"\n",
    "                src_k, src_v,  src_lengths = zip(*batch)\n",
    "\n",
    "                ## padding\n",
    "                src_k = pad_sequence([torch.tensor(data) for data in src_k], batch_first=True , padding_value=self.pad)\n",
    "                src_v = pad_sequence([torch.tensor(data) for data in src_v], batch_first=True , padding_value=self.pad)  \n",
    "\n",
    "                ## convert\n",
    "                src_lengths = torch.tensor(src_lengths)\n",
    "\n",
    "                batch = {'src_k':src_k, \n",
    "                         'src_v':src_v, \n",
    "                         'src_lengths':src_lengths, \n",
    "                        }\n",
    "\n",
    "                return batch\n",
    "            return fn\n",
    "    def __len__(self):\n",
    "        return len(self._dataset['src_k'])\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if self.setname == 'train' or self.setname == 'valid':\n",
    "            src_k = self._dataset['src_k'][idx]\n",
    "            src_v = self._dataset['src_v'][idx]\n",
    "            src_lengths = self._dataset['src_lengths'][idx]\n",
    "            tgt = self._dataset['tgt'][idx]\n",
    "            tgt_lengths = self._dataset['tgt_lengths'][idx]\n",
    "            alignment = self._dataset['alignment'][idx]\n",
    "            template = self._dataset['template'][idx]\n",
    "            template_lengths = self._dataset['tgt_lengths'][idx]\n",
    "\n",
    "            sample = (src_k, src_v,  src_lengths, tgt, tgt_lengths, alignment, template, template_lengths)\n",
    "\n",
    "        elif self.setname == 'test':\n",
    "            src_k = self._dataset['src_k'][idx]\n",
    "            src_v = self._dataset['src_v'][idx]\n",
    "            src_lengths = self._dataset['src_lengths'][idx]\n",
    "\n",
    "            sample = (src_k, src_k, src_lengths)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "3b49fd2b-13d5-444b-a075-cb87b27ed444",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = Rotowire()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "97c5fd2b-7be1-4bf4-a375-8ea69bd22b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for batch in a._dataset['valid']:\n",
    "    total+=len(batch['src_k'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "575e35cd-ef25-4268-a83d-01cc4c69517c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727\n"
     ]
    }
   ],
   "source": [
    "print(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f658e4f7-8585-4094-ae0d-7bb76fb55f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
